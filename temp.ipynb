{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f077864b520>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "data_segments = [\"train\", \"val\"] \n",
    "\n",
    "data_dir = \"../data/hymenoptera_data/\"\n",
    "img_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                for x in data_segments}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(img_datasets[x], batch_size=4, shuffle=True, num_workers=4)\n",
    "                for x in data_segments}\n",
    "\n",
    "dataset_sizes = {x: len(img_datasets[x]) for x in data_segments}\n",
    "class_names = img_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "from pickletools import optimize\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f\">>> Epoch {epoch+1} / {num_epochs}\")\n",
    "        print('-'*10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    out = model(inputs)\n",
    "                    _, preds = torch.max(out, 1)\n",
    "                    loss = criterion(out, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == True:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                plt.imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 1 / 25\n",
      "----------\n",
      "train Loss: 0.5386 Acc: 0.7090\n",
      "val Loss: 0.4151 Acc: 0.7974\n",
      "\n",
      ">>> Epoch 2 / 25\n",
      "----------\n",
      "train Loss: 0.5833 Acc: 0.7418\n",
      "val Loss: 0.3163 Acc: 0.9085\n",
      "\n",
      ">>> Epoch 3 / 25\n",
      "----------\n",
      "train Loss: 0.3923 Acc: 0.8279\n",
      "val Loss: 0.3302 Acc: 0.8824\n",
      "\n",
      ">>> Epoch 4 / 25\n",
      "----------\n",
      "train Loss: 0.4406 Acc: 0.8156\n",
      "val Loss: 0.5135 Acc: 0.8431\n",
      "\n",
      ">>> Epoch 5 / 25\n",
      "----------\n",
      "train Loss: 0.7908 Acc: 0.7541\n",
      "val Loss: 0.7704 Acc: 0.7255\n",
      "\n",
      ">>> Epoch 6 / 25\n",
      "----------\n",
      "train Loss: 0.4765 Acc: 0.8320\n",
      "val Loss: 0.2899 Acc: 0.9020\n",
      "\n",
      ">>> Epoch 7 / 25\n",
      "----------\n",
      "train Loss: 0.5061 Acc: 0.8197\n",
      "val Loss: 0.1846 Acc: 0.9346\n",
      "\n",
      ">>> Epoch 8 / 25\n",
      "----------\n",
      "train Loss: 0.4566 Acc: 0.8197\n",
      "val Loss: 0.2088 Acc: 0.9412\n",
      "\n",
      ">>> Epoch 9 / 25\n",
      "----------\n",
      "train Loss: 0.5103 Acc: 0.7828\n",
      "val Loss: 0.2662 Acc: 0.9020\n",
      "\n",
      ">>> Epoch 10 / 25\n",
      "----------\n",
      "train Loss: 0.3638 Acc: 0.8484\n",
      "val Loss: 0.3032 Acc: 0.9085\n",
      "\n",
      ">>> Epoch 11 / 25\n",
      "----------\n",
      "train Loss: 0.3315 Acc: 0.8525\n",
      "val Loss: 0.4964 Acc: 0.8627\n",
      "\n",
      ">>> Epoch 12 / 25\n",
      "----------\n",
      "train Loss: 0.5357 Acc: 0.8279\n",
      "val Loss: 0.3865 Acc: 0.8758\n",
      "\n",
      ">>> Epoch 13 / 25\n",
      "----------\n",
      "train Loss: 0.5501 Acc: 0.8156\n",
      "val Loss: 0.3430 Acc: 0.8954\n",
      "\n",
      ">>> Epoch 14 / 25\n",
      "----------\n",
      "train Loss: 0.3895 Acc: 0.8484\n",
      "val Loss: 0.4296 Acc: 0.8627\n",
      "\n",
      ">>> Epoch 15 / 25\n",
      "----------\n",
      "train Loss: 0.3811 Acc: 0.8648\n",
      "val Loss: 0.2421 Acc: 0.9216\n",
      "\n",
      ">>> Epoch 16 / 25\n",
      "----------\n",
      "train Loss: 0.4284 Acc: 0.8443\n",
      "val Loss: 0.4029 Acc: 0.8954\n",
      "\n",
      ">>> Epoch 17 / 25\n",
      "----------\n",
      "train Loss: 0.4644 Acc: 0.8402\n",
      "val Loss: 0.4294 Acc: 0.8758\n",
      "\n",
      ">>> Epoch 18 / 25\n",
      "----------\n",
      "train Loss: 0.4386 Acc: 0.7951\n",
      "val Loss: 0.2772 Acc: 0.8954\n",
      "\n",
      ">>> Epoch 19 / 25\n",
      "----------\n",
      "train Loss: 0.2077 Acc: 0.9344\n",
      "val Loss: 0.2456 Acc: 0.9281\n",
      "\n",
      ">>> Epoch 20 / 25\n",
      "----------\n",
      "train Loss: 0.4013 Acc: 0.8484\n",
      "val Loss: 0.3485 Acc: 0.9150\n",
      "\n",
      ">>> Epoch 21 / 25\n",
      "----------\n",
      "train Loss: 0.3755 Acc: 0.8607\n",
      "val Loss: 0.2645 Acc: 0.9216\n",
      "\n",
      ">>> Epoch 22 / 25\n",
      "----------\n",
      "train Loss: 0.3081 Acc: 0.8893\n",
      "val Loss: 0.2101 Acc: 0.9477\n",
      "\n",
      ">>> Epoch 23 / 25\n",
      "----------\n",
      "train Loss: 0.4804 Acc: 0.8238\n",
      "val Loss: 0.3497 Acc: 0.8954\n",
      "\n",
      ">>> Epoch 24 / 25\n",
      "----------\n",
      "train Loss: 0.2419 Acc: 0.9098\n",
      "val Loss: 0.3328 Acc: 0.9150\n",
      "\n",
      ">>> Epoch 25 / 25\n",
      "----------\n",
      "train Loss: 0.4337 Acc: 0.8484\n",
      "val Loss: 0.4022 Acc: 0.8693\n",
      "\n",
      "Training complete in 0m 57s\n",
      "Best val Acc: 0.947712\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 224, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m visualize_model(model_ft)\n",
      "\u001b[1;32m/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb Cell 8\u001b[0m in \u001b[0;36mvisualize_model\u001b[0;34m(model, num_images)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ax\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m ax\u001b[39m.\u001b[39mset_title(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredicted: \u001b[39m\u001b[39m{\u001b[39;00mclass_names[preds[j]]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m plt\u001b[39m.\u001b[39;49mimshow(inputs\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mdata[j])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m images_so_far \u001b[39m==\u001b[39m num_images:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/toghrul/ml_projects/hymenoptera/hymenoptera-torch/temp.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain(mode\u001b[39m=\u001b[39mwas_training)\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    451\u001b[0m     warn_deprecated(\n\u001b[1;32m    452\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    455\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/matplotlib/pyplot.py:2640\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[1;32m   2635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[1;32m   2636\u001b[0m         X, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, aspect\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, interpolation\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2637\u001b[0m         alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, origin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[1;32m   2638\u001b[0m         interpolation_stage\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filternorm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterrad\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m,\n\u001b[1;32m   2639\u001b[0m         resample\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2640\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mimshow(\n\u001b[1;32m   2641\u001b[0m         X, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm, aspect\u001b[39m=\u001b[39;49maspect,\n\u001b[1;32m   2642\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation, alpha\u001b[39m=\u001b[39;49malpha, vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[1;32m   2643\u001b[0m         vmax\u001b[39m=\u001b[39;49mvmax, origin\u001b[39m=\u001b[39;49morigin, extent\u001b[39m=\u001b[39;49mextent,\n\u001b[1;32m   2644\u001b[0m         interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[1;32m   2645\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm, filterrad\u001b[39m=\u001b[39;49mfilterrad, resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m   2646\u001b[0m         url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[1;32m   2647\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2648\u001b[0m     sci(__ret)\n\u001b[1;32m   2649\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:456\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[1;32m    451\u001b[0m     warn_deprecated(\n\u001b[1;32m    452\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    455\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/matplotlib/__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5488\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5481\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5482\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap, norm, interpolation,\n\u001b[1;32m   5483\u001b[0m                       origin, extent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[1;32m   5484\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[1;32m   5485\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5486\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5488\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5489\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5490\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5491\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sign-lang/lib/python3.9/site-packages/matplotlib/image.py:715\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    714\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> 715\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    716\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    718\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    719\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 224, 224) for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGwAAABeCAYAAADG1PFrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAE00lEQVR4nO2Ya4hVVRSAvzXjWI2UNBHV5J0LkfSwHyKYBGMIGUV/LCIjYrA0JomQisLGpPpRg9ID+iMKkdPTCMIgoqKsBlEKCaKHL1JnvLcmsNFBK8KK3Y+9TmyO9849F0ZnVqwPBva5az/WOd9+MRJCwLFDy2Qn4DSHCzOGCzOGCzOGCzOGCzPGpAsTkSERWazlNSLy8hkYc5GIVJuoH0Tk8tOZU1GmTXYCKSGE/iL1RGQAqIYQ1p7ejKYeE7rCRGRKTYD/JSGEcf+AIaAP2A0cAzYDZ2tsEVAFVgO/AK8TJ8HjwAFgFHgH6Ej66wGGNfaE9r9YY08DbyR1u4GdwBhQAe4BeoG/gJPAb8D7WrcTeBc4AhwCViX9nAMMaP67gceIK7Th+2v7AKwCDgK/As8BLUl8ObBH+/8YKCexK4FPgKPAPmBpErtF8zkB/AQ82jCXgsK+B0pAB7ADeCYR9jewHjhLP8xDwJfALP1tE7BF61+tH/l6jb2o7U8RBnTpi9wFtAEXAHM1NpDloM8twNfAk8B04DL9uDdpfB2wXfMv6ftUk/YbgA0NhH2u7buA/cB9GrsV+BG4injErAV2amyGTrR7NTZPhc/R+AiwUMvnA/MmStjK3Kw4kAg7ia44/W0PcEPyfAlxRUzTD/p2Epuh7WsJ6wO21skpL2wBcDhXpw/YrOWDwM1JrJfmV1ja/gFgm5Y/BFbkJs8fQBm4E9ie62sT8JSWDwP3A+cVzaXoGVZJysPE7SfjSAjhz+S5DGwVkTERGVOB/wAXabv/+goh/E7cGmtRIm6rRSgDndmYOu4aHZP8uPoOzVLvG5SBl5JxjwICXKqxBbm87gYu1ra3ExfAsIgMish1jZIoekkoJeUu4OfkOf/v/gqwPISwI9+JiIwQt47suZ241dWiAlxbJ1ZrzEMhhNl16o8Q3+EHfe6qU2888u2zb1ABng0hvJlvICJlYDCEcGOtDkMIu4AlItIGPEg870u16qaNimyJ3xHPpA7iWdCfbInVXP2HgS/Qgxe4EFii5TnEM6ybeNY8T+MzbClxYqVn2DrgrWTMVuIZtpp4jrYC1wDzNb4eGCSeE7OAb/N5F9gSt2n7ErAX6NXYbcQzMTuXZgJ3aPlc4mrsIZ7DbcB84qSdTlxtM7XuCmBoos6w7JY4BrwKtI8jrAV4hHgjOkHc1vqT+DLi3l3klrgQ+Ao4TpzJy/T32cA3ms97+lsnsIV4Wz1GvPhk/bYDr2n9U26JwEZgYwNh2S1xFHgBaE3iPcRJneX5ShK7AviAeHsdBT4D5qqwjzTX48AuoLuRD9FO6yIiQ8Qb0afjVnTOCJP+rymnOVyYMRpuic7UwleYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMVyYMf4FXoKZjCzzyosAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_model(model_ft)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('sign-lang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96a4e4d8fc4dcb6ce321df308d690f3398dc6d289b3efb6c91f90112c618c739"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
